{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4350c4f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"midterm2_coding.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df96803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, Model, Sequential, losses, optimizers, metrics\n",
    "\n",
    "from helper import plot_df, resample, data_generator, data_generator2\n",
    "from helper import decode_image, load_and_preprocess_image, load_tfrecord_dataset,\\\n",
    "                   parse_example\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3de67146",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this coding exercise you will build a model that predicts 3 properties of an individual from a picture of their face: age, ethnicity, and gender.\n",
    "\n",
    "You should run this notebook on the OnDemand Jupyter environment for the course. That environment has all required libraries so you won't need to use the included requirements.txt file. The model you will build is very small so this can run on either the CPU or GPU onstance.\n",
    "\n",
    "This Dataframe gives us an idea of what we are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aa72e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataframe\n",
    "df = pd.read_csv('data/face_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b82487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map integer encodings to class labels\n",
    "# label ordering based on prevelance and taken from the Kaggle dataset release:\n",
    "# https://www.kaggle.com/datasets/nipunarora8/age-gender-and-ethnicity-face-data-csv\n",
    "names_ethnicity = ['white', 'black', 'asian', 'indian', 'other']\n",
    "name_genders = ['male', 'female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59263b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d4b7058",
   "metadata": {},
   "source": [
    "We'll use a helper function to `resample` to make sure the ethnicities are equally represented in a new Dataframe.\\\n",
    "Please don't change `OBSERVATION_PER_CLASS` from the default of 7500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dd0477",
   "metadata": {},
   "outputs": [],
   "source": [
    "OBSERVATIONS_PER_CLASS = 7500\n",
    "df_resampled = resample(df, unbalanced_col='ethnicity', n_per_class=OBSERVATIONS_PER_CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6cb957",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df(df_resampled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f297bc08",
   "metadata": {},
   "source": [
    "That looks a little better, though not perfect. We'll settle for that for now."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ed4f338f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Train / Validation / Test Split\n",
    "\n",
    "Using your resampled data and `train_test_split`, create a test set consisting of 20% of the resampled dataset. Then set aside 10% of what was left over from the first split as a validation set. Whatever remains will be your train set.\n",
    "\n",
    "You should stratify your splits on both 'ethnicity' and 'gender' and use a random state of 109.\n",
    "\n",
    "Store the results in `train_df`, `val_df`, and `test_df`.\n",
    "\n",
    "**Hint:** The `stratify` argument can be passed a DataFrame with one or more columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9710b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the dataframe into train and validation sets\n",
    "train_df_temp, test_df = ...\n",
    "train_df, val_df = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabd7562",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"data_split\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ddc9f2c",
   "metadata": {},
   "source": [
    "**Creating Datasets**\n",
    "\n",
    "For the sake of consistency, to minimize mememory and storage space, and to make training as fast as possible, we will provide pre-made train, validation, and test datasets in the form of TF Dataset pipelines.\n",
    "\n",
    "These have been balanced for both ethnicity and gender within each ethnicity, similar to what you attempted above in the splitting.\n",
    "\n",
    "Run the code below to create train, validation, and test datasets. \n",
    "\n",
    "Later you may want to play with the batch size, but remember to stay conservative to prevent the kernel from dying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df533fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 # num images in a generator batch\n",
    "IMG_DIM = (32, 32) # orignal images are 48x48 dataset pipeline resizes to 32x32\n",
    "train_tfrecord_file = 'data/faces_train_balanced.tfrecord'\n",
    "val_tfrecord_file = 'data/faces_val_balanced.tfrecord'\n",
    "test_tfrecord_file = 'data/faces_test_balanced.tfrecord'\n",
    "\n",
    "train_dataset = load_tfrecord_dataset(train_tfrecord_file, IMG_DIM, BATCH_SIZE)\n",
    "val_dataset = load_tfrecord_dataset(val_tfrecord_file, IMG_DIM, BATCH_SIZE)\n",
    "test_dataset = load_tfrecord_dataset(test_tfrecord_file, IMG_DIM, BATCH_SIZE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66ee7518",
   "metadata": {},
   "source": [
    "We can see what the datasets produce with this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e20b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect what the datasets produce\n",
    "train_dataset.element_spec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d5bde55",
   "metadata": {},
   "source": [
    "The **inputs** are 32x32 grayscale images of faces \n",
    "(the single channel has been duplicated twice to make them 32x32x3 to work well with models trained on color images.)\n",
    "\n",
    "The **target** variables match the order of the columns in the Dataframe above.\n",
    "- The first target is the **age** variable (continous).\n",
    "- The second target is **ethnicity** (categorical)\n",
    "- The third target is **gender** (binary in this dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24917cde",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Transfer Learning with BabyNet\n",
    "\n",
    "The base of your model will be a very tiny CNN classifier pre-trained on the CIFAR-10 dataset (~80% test accuracy). The model is 10% the size of MobileNetV3Small; We call it `BabyNet`. \n",
    "\n",
    "Use keras to load this pre-trained model from the `BabyNet.keras` file and store the model in a variable called `babynet`. Then inspect the model summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf16b9c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the 'BabyNet' model\n",
    "babynet = ...\n",
    "babynet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bca44e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"load_babynet\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72459e02",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Chop Off the Top!\n",
    "\n",
    "We want to leverage the feature extraction ability of the convolutional section of the pre-trained network (conv2d & pooling) since we think these features will generalize to our own task of predicting age, ethnicity, and gender from pictures of faces, (even though the CIFAR-10 dataset contains no human faces!)\n",
    "\n",
    "But we *do not care* about the original 'top' of BabyNet since these final layers are more related to the specific CIFAR-10 classification task.\n",
    "\n",
    "Create a new model, `base_model`, with the same `inputs` as `babynet` but whose outputs come from the final layer in the convolutional section of `babynet` (i.e., before the dimensions get flattened). Be sure to also give your new model the name attribute 'base_model' when you construct it.\n",
    "\n",
    "Printing the summary is always helpful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2b804e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "base_model = ...\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed48ee82",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"choptop\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c95e6d40",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Freeze Weights\n",
    "\n",
    "In our initial round of training we don *not* want to mangle the pre-trained weights because we think they will be useful. So you should **set the base model's weight to be not trainable**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a1d035",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "# Freeze the base model weights for transfer learning\n",
    "base_model.trainable = ...\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc43123",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"freeze\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5de0f542",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Data Augmentation\n",
    "\n",
    "Create a small model to perform data augmentation. It should have one layer to perform a random, horizontal 'flip' followed by another layer to add a small amount of GaussianNoise. Store this model in the variable `data_augmentation` and give the the name attribute \"data_aug\".\n",
    "\n",
    "**NOTE:** Do *not* change the name attributes of any of the layers as the default names will be used for comparison in the tests.\n",
    "\n",
    "**Hint:**\n",
    "- See what layers are available in `tf.keras.layers`\n",
    "- It maybe be easier for you if you also use an input \"layer\"\n",
    "- Images are already normalized to be between 0 and 1 (what BabyNet expects) so the amount of noise you want to add should be very small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e4681b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "data_augmentation = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbfb12b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# display data augmentation model summary\n",
    "data_augmentation.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb794ff",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"data_aug\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aec0054f",
   "metadata": {},
   "source": [
    "Run the code below to visualize some augmentation examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bec915b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate variants of the first image from the training dataset\n",
    "for images, labels in train_dataset.take(1):\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    first_image = images[0]\n",
    "    for i in range(4):\n",
    "        ax = plt.subplot(2, 2, i + 1)\n",
    "        # apply the transformation layers\n",
    "        augmented_image = data_augmentation(\n",
    "            tf.expand_dims(first_image, 0), training=True\n",
    "        )\n",
    "        # plt.imshow(augmented_image[0].numpy().astype(\"int32\"))\n",
    "        plt.imshow(augmented_image[0])\n",
    "        plt.axis(\"off\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c681a09",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Building the Model\n",
    "\n",
    "Construct your model and store in the variable called `model`. It's structure should look like this:\n",
    "- input \"layer\"\n",
    "- data augmentation\n",
    "- base_model\n",
    "- new intermediate layer(s)\n",
    "- 3 output layers, give them the name attributes 'age_output', 'ethnicity_output', 'gender_output'\n",
    "\n",
    "**Hint:**\n",
    "- The output of the base model is 3D (64 8x8 feature maps). Your new intermediate layer(s) will need too convert this output to 1D before it can be passed on to your output layers. We saw *at least 2 different ways* of doing this in class. Again, see what `tf.keras.layers` has to offer.\n",
    "- You can experiment with the architecture you add to the base modelm *start out small and simple*. You can pass all the tests in this notebook with less than 100k total parameters in your full network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900cbfff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "model = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f688515c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# display summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071b476f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"build_model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "482ffa77",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Compile the Model\n",
    "\n",
    "When dealing with multiple outputs it is useful to pass dictionaries for both the `loss` and `metrics` arguments of `compile`. The dictionary keys are the layer names and their values are the losses or metrics themselves.\n",
    "\n",
    "Choose appropriate losses for each of the 3 outputs. \n",
    "\n",
    "You should monitor the following metrics:\n",
    "- age: mean absolute error\n",
    "- ethnicity: accuracy\n",
    "- gender: accuracy\n",
    "\n",
    "Create the dictionaries `loss` and `metrics` to pass to the `compile function`.\n",
    "\n",
    "**Note:** The keys should be *strings* representing the relevant loss or metric (Keras understands these). These strings are expected to be lowercase and any spaces should be replaced by underscores.\n",
    "\n",
    "For the **optimizer**, we recomment the Adam optimizer, though you might want to try something slighlty higher than the default learning rate.\n",
    "\n",
    "Save your optimizer as `optimizer1`.\n",
    "\n",
    "You can experiment with the `loss_weights` argument of the optimizer if you like, but it should not be necessary to pass all tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43aef41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "optimizer1 = ...\n",
    "loss = ...\n",
    "metrics = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20534bf",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"compile_model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d22c6b8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Initial Training\n",
    "\n",
    "Train the new layers you added to the base model. You'll want to do at least 3 epochs. More would likely help, but start small while you're still testing things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023ff233",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "initial_epochs = ...\n",
    "\n",
    "history1 = model.fit(train_dataset,\n",
    "                    epochs=initial_epochs,\n",
    "                    validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c06f95",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"initial_training\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30d5c1a8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Unfreeze Base Model & Recompile with New Optimizer\n",
    "\n",
    "Now we will fine-tune the base model. First, you'll need to unfreeze its weights. Remember that you need to recompile the model for the change to take effect. When you print the summary the model should now show many more trainable parameters in the summary.\n",
    "\n",
    "When recompiling in preparation for fine tuning you should choose a sensible **learning rate** for the new optimizer. Call this new optimizer, `optimizer2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da04989a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# unfreeze the base model and compile\n",
    "# your code here\n",
    "optimizer2 = ...\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db07c26d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# display summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11a9fbb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"unfreeze\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86b11e39",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Fine-Tuning\n",
    "\n",
    "Now that *all* the weights in the network are trainable, train your model for a few more epochs. You'll probably want to do at least 2, but more may be beneficial depending on your initial training and model architecture.\n",
    "\n",
    "**Hint:** remember that adjusting the weights of the pre-trained model also has the potential to be *destructive* if the learning rate is too high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb96262",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "fine_tune_epochs = ...\n",
    "total_epochs = initial_epochs + fine_tune_epochs\n",
    "\n",
    "history2 = model.fit(train_dataset,\n",
    "                    initial_epoch=initial_epochs,  # Resume training\n",
    "                    epochs=total_epochs,\n",
    "                    validation_data=val_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56dd36de",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Display Full Training History**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72677825",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "full_history = {}\n",
    "for key in history1.history.keys():\n",
    "    full_history[key] = history1.history[key] + history2.history[key]\n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize=(9,4))\n",
    "axs = axs.flatten()\n",
    "\n",
    "axs[0].plot(full_history['val_age_output_'+metrics['age_output']], label='train')\n",
    "axs[0].plot(full_history['age_output_'+metrics['age_output']], label='validation')\n",
    "axs[0].set_ylabel('MAE')\n",
    "axs[0].set_title('Age')\n",
    "\n",
    "axs[1].plot(full_history['ethnicity_output_'+metrics['ethnicity_output']], label='train')\n",
    "axs[1].plot(full_history['val_ethnicity_output_'+metrics['ethnicity_output']], label='validation')\n",
    "axs[1].axhline(0.2, c='r', ls=':', label='random chance')\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "axs[1].set_title('Ethnicity')\n",
    "\n",
    "axs[2].plot(full_history['gender_output_'+metrics['gender_output']], label='train')\n",
    "axs[2].plot(full_history['val_gender_output_'+metrics['gender_output']], label='validation')\n",
    "axs[2].axhline(0.5, c='r', ls=':', label='random chance')\n",
    "axs[2].set_ylabel('Accuracy')\n",
    "axs[2].set_title('Gender')\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_xticks(list(range(total_epochs))[::3])\n",
    "    x = np.arange(initial_epochs-1, total_epochs-1, 0.1)\n",
    "    ax.fill_between(x, *ax.get_ylim(), alpha=0.2, color='green', label='fine-tuning')\n",
    "    ax.legend();\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015d5e44",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"fine-tuning\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c1df5b5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Evaluate on Test Dataset\n",
    "\n",
    "Evaluate your final model on test dataset and store the results in `test_eval`.\n",
    "\n",
    "You should be able to achieve:\n",
    "- Age MAE < 14\n",
    "- Ethnicity Accuracy > 0.3\n",
    "- Gender Accuracy > 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f05009",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "test_eval = ...\n",
    "print(f\"Test Age MAE: {test_eval[4]:.2f}\")\n",
    "print(f\"Test Ethnicity ACC: {test_eval[5]:.2f}\")\n",
    "print(f\"Test Gender ACC: {test_eval[6]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ac6c21",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"test_eval\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7c2d5f2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Predict on a Test Batch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2da35bbd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Take one batch from the test dataset and store it as `test_batch`.\n",
    "\n",
    "Next, use your model to predict on this batch and store the predictions in `y_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b332273e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_batch = ...\n",
    "y_pred = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd35e3cf",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"predictions\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd74f0d1",
   "metadata": {},
   "source": [
    "### You're almost there!\n",
    "\n",
    "**There is no more code for you to enter after this point. If your notebook runs to the end you pass the final test!**\n",
    "\n",
    "**Processing Prediction Vectors**\n",
    "\n",
    "Here we create vectors `age_pred`, `eth_pred`, and `gen_pred` each containing the predicted values of the 3 target variables in the validation batch.\n",
    "\n",
    "These vectors are all be flat (1D) and they should all contain *integers*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96774f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_pred = np.round(y_pred[0].flatten()).astype(int)\n",
    "eth_pred = y_pred[1].argmax(axis=1)\n",
    "gen_pred = (y_pred[2].flatten() >= 0.5).astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7fa83b3b",
   "metadata": {},
   "source": [
    "Use this code to extract the images and target variables from the batch. Note the shapes of these objects. You may want to investigate them further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1716a9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input images and targets from batch\n",
    "images, labels =  next(test_batch.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c7097b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('images.shape:', images.shape)\n",
    "print('len(labels):', len(labels))\n",
    "print('labels[0].shape:', labels[0].shape)\n",
    "print('labels[1].shape:', labels[1].shape)\n",
    "print('labels[2].shape:', labels[2].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "11f6cb9b",
   "metadata": {},
   "source": [
    "**True Labels**\n",
    "\n",
    "Here are the true vectors `age_true`, `eth_true`, and `gen_true` each containing the true values of the 3 target variables in the validation batch.\n",
    "\n",
    "These vectors are all be flat (1D) and they all contain integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdb00fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_true, eth_true, gen_true = [y.flatten().astype(int) for y in labels]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f454d47",
   "metadata": {},
   "source": [
    "Run the code below to inspect some example predictions from your validation batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690d58fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4,4, figsize=(16,16))\n",
    "axs = axs.flatten()\n",
    "for i in range(16):\n",
    "    axs[i].imshow(images[i])\n",
    "    pred_str = f'{age_pred[i]} {names_ethnicity[eth_pred[i]]} {name_genders[gen_pred[i]]}'\n",
    "    true_str = f'{age_true[i]} {names_ethnicity[eth_true[i]]} {name_genders[gen_true[i]]}'\n",
    "    axs[i].set_title('[PRED]\\n' + pred_str+'\\n'+'[TRUE]\\n'+ true_str)\n",
    "    axs[i].set_xticks([])\n",
    "    axs[i].set_yticks([])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2fe809b0",
   "metadata": {},
   "source": [
    "OK, so the results are probably not the greatest given the time and base model's size, but with such a tiny model and dataset it is still surprising we can do much better than guessing on all there tasks at once! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45b2d25",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"you_did_it\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74072a14",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "Run this to generate the zip you need to upload to Gradescope. Make sure all earlier cells were run and their output is still visible (Restart & Run All is always the best way)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d928560",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(filtering=False, pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8ea37f",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "build_model": {
     "name": "build_model",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_output_count(model):\n...     t1 = len(model.outputs) == 3\n...     assert t1, 'Your model should have 3 outputs'\n>>> test_output_count(model)\n",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> def test_categorical_output(model):\n...     t1 = model.outputs[1].shape == [None, 5]\n...     assert t1, 'The 2nd output should be making predictions for a categorical variable. ' + 'How many categories are there for this variable? Check your output dimensions.'\n>>> test_categorical_output(model)\n",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> def test_age_output(tf, model):\n...     t1 = model.get_layer('age_output').activation == tf.keras.activations.linear\n...     t1_b = model.get_layer('age_output').activation == tf.keras.activations.relu\n...     assert t1 or t1_b, 'Age is a continuous variable. Check this output layer.'\n>>> test_age_output(tf, model)\n",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> def test_ethnicity_output(tf, model):\n...     t1 = model.get_layer('ethnicity_output').activation == tf.keras.activations.softmax\n...     assert t1, 'Ethnicity is a categorical variable. Check this output layer.'\n>>> test_ethnicity_output(tf, model)\n",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> def test_gender_output(tf, model):\n...     t1 = model.get_layer('gender_output').activation == tf.keras.activations.sigmoid\n...     assert t1, \"In this dataset, gender is a binary variable. Check this output layer. Be conservative with the shape. Don't do with more what can be done with less! (hint, hint, look at the output activation and shape and think abou the variable!)\"\n>>> test_gender_output(tf, model)\n",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> def test_data_aug_insert(model):\n...     t1 = model.get_layer('data_aug')\n...     assert t1, \"couldn't find the data augmentation model as part of your architecture. Do you give it the name attribute 'data_aug'?\"\n>>> test_data_aug_insert(model)\n",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> def test_base_model_insert(model):\n...     t1 = model.get_layer('base_model')\n...     assert t1, \"couldn't find the base model as part of your architecture\"\n>>> test_base_model_insert(model)\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "choptop": {
     "name": "choptop",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_choptop(base_model):\n...     t1 = babynet.layers[-5].output.shape == [None, 8, 8, 64]\n...     assert t1, \"Remember, we don't want to include any of the layers after the convolutional section!\"\n>>> test_choptop(base_model)\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "compile_model": {
     "name": "compile_model",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_optimizer1(optimizer1):\n...     t1 = optimizer1.learning_rate.numpy() > 0.001\n...     assert t1, 'You should use a learning rate higher than the default!'\n>>> test_optimizer1(optimizer1)\n",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> def test_model_loss(loss):\n...     expected_loss = {'age_output': ['mse', 'mean_squared_error', 'mae', 'mean_absolute_error'], 'ethnicity_output': ['sparse_categorical_crossentropy'], 'gender_output': ['binary_crossentropy', 'bce']}\n...     for key, expected_values in expected_loss.items():\n...         t1 = key in loss\n...         assert t1, f'Missing key \"{key}\" in loss dictionary'\n...         t2 = loss[key].lower() in expected_values\n...         assert t2, f'Unexpected value \"{loss[key]}\" for key \"{key}\" in loss dictionary. Make sure to use strings when specifying the losses! Think about the variable type and dimensions for each output!'\n>>> test_model_loss(loss)\n",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> def test_model_metrics(metrics):\n...     expected_metrics = {'age_output': ['mae', 'mean_absolute_error'], 'ethnicity_output': ['accuracy', 'acc'], 'gender_output': ['accuracy', 'acc']}\n...     for key, expected_values in expected_metrics.items():\n...         t1 = key in metrics\n...         assert t1, f'Missing key \"{key}\" in metrics dictionary'\n...         t2 = metrics[key].lower() in expected_values\n...         assert t2, f'Unexpected value \"{metrics[key]}\" for key \"{key}\" in metrics dictionary. Make sure to use strings to specify the metrics! Think about the variable type and dimensions for each output!'\n>>> test_model_metrics(metrics)\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "data_aug": {
     "name": "data_aug",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_data_aug(data_augmentation, IMG_DIM):\n...     t1 = data_augmentation.inputs[0].shape == (None, *IMG_DIM, 3)\n...     assert t1, 'The data aug model should have an input shape that allows it to take in images from the datasets'\n...     t2 = data_augmentation.layers[-2].name.startswith('random_flip')\n...     assert t2, 'A layer to perform a random flip should be the 2nd to last layer in the data aug model'\n...     t3 = data_augmentation.layers[-1].name.startswith('gaussian_noise')\n...     assert t3, 'Gaussian Noise should be the final layer in the data aug model'\n...     t4 = data_augmentation.outputs[0].shape == (None, *IMG_DIM, 3)\n...     assert t4, 'The output shape of the data aug model should be the same as the input shape you specified.'\n...     t5 = data_augmentation.name == 'data_aug'\n...     assert t5, \"Did you forget to give your data aug model the name 'data_aug'?\"\n>>> test_data_aug(data_augmentation, IMG_DIM)\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "data_split": {
     "name": "data_split",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_split(np, test_df, train_df, val_df, df_resampled):\n...     t1 = np.isclose(len(test_df), int(len(df_resampled) * 0.2), atol=1)\n...     assert t1, 'Wrong number of observations in test_df'\n...     t2 = np.isclose(len(train_df), int(len(df_resampled) * 0.8 * 0.9), atol=1)\n...     assert t2, 'Wrong number of observations in train_df'\n...     t3 = np.isclose(len(val_df), int(len(df_resampled) * 0.8 * 0.1), atol=1)\n...     assert t3, 'Wrong number of observations in val_df'\n>>> test_split(np, test_df, train_df, val_df, df_resampled)\n",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> def test_stratify(np, train_test_split, df_resampled):\n...     train_df_temp, test_df_sol = train_test_split(df_resampled, test_size=0.2, random_state=109, stratify=df_resampled[['ethnicity', 'gender']])\n...     train_df_sol, val_df_sol = train_test_split(train_df_temp, test_size=0.1, random_state=109, stratify=train_df_temp[['ethnicity', 'gender']])\n...     t1 = np.allclose(test_df.ethnicity.value_counts().values, test_df_sol.ethnicity.value_counts().values)\n...     assert t1, \"test_df's ethnicity proportions are not very close. Did you stratify?\"\n...     t2 = np.allclose(train_df.ethnicity.value_counts().values, train_df_sol.ethnicity.value_counts().values)\n...     assert t2, \"train_df's ethnicity proportions are not very close. Did you stratify?\"\n...     t3 = np.allclose(val_df.ethnicity.value_counts().values, val_df_sol.ethnicity.value_counts().values)\n...     assert t3, \"val_df's ethnicity proportions are not very close. Did you stratify?\"\n...     t4 = np.allclose(test_df.gender.value_counts().values, test_df_sol.gender.value_counts().values)\n...     assert t4, \"test_df's gender proportions are not very close. Did you stratify?\"\n...     t5 = np.allclose(train_df.gender.value_counts().values, train_df_sol.gender.value_counts().values)\n...     assert t5, \"train_df's gender proportions are not very close. Did you stratify?\"\n...     t6 = np.allclose(val_df.gender.value_counts().values, val_df_sol.gender.value_counts().values)\n...     assert t6, \"val_df's gender proportions are not very close. Did you stratify?\"\n>>> test_stratify(np, train_test_split, df_resampled)\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "fine-tuning": {
     "name": "fine-tuning",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_fine_tuning(history2, fine_tune_epochs):\n...     t1 = len(history2.history['age_output_loss']) == fine_tune_epochs\n...     assert t1, f'After fine tuning, your history2 object should have {fine_tune_epochs} entries to match each epoch in fine_tune_epochs.'\n>>> test_fine_tuning(history2, fine_tune_epochs)\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "freeze": {
     "name": "freeze",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_freeze(np, tf, base_model):\n...     t1 = (np.sum([tf.keras.backend.count_params(w) for w in base_model.trainable_weights]) == 0,)\n...     assert t1, 'The number of trainable parameters in the base model should be zero. ' + 'Remember we need to set all weights in the base model to be non-trainable'\n>>> test_freeze(np, tf, base_model)\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "initial_training": {
     "name": "initial_training",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_initial_training(history1, initial_epochs):\n...     t1 = len(history1.history['age_output_loss']) == initial_epochs\n...     assert t1, f'After training, your history1 object should have {initial_epochs} entries to match each epoch in initial_epochs.'\n>>> test_initial_training(history1, initial_epochs)\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "load_babynet": {
     "name": "load_babynet",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_babynet_load(babynet):\n...     t1 = babynet.layers[-1].name.lower() == 'cifar_output'\n...     t2 = babynet.layers[-1].output.shape == [None, 10]\n...     assert t1 and t2, 'Expected base model not loaded. The babynet.keras model file is in your working directory!'\n>>> test_babynet_load(babynet)\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "predictions": {
     "name": "predictions",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_y_pred(y_pred):\n...     t1 = len(y_pred) == 3\n...     assert t1, 'Your y_pred should have 3 sets of predictions in it!'\n>>> test_y_pred(y_pred)\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "test_eval": {
     "name": "test_eval",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_test_eval_age(model, test_eval):\n...     _, _, _, _, eval_age, eval_eth, eval_gen = test_eval\n...     t1 = eval_age < 14\n...     assert t1, f'Your age MAE on the test data should is too high! ({eval_age})'\n>>> test_test_eval_age(model, test_eval)\n",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> def test_test_eval_eth(model, test_eval):\n...     _, _, _, _, eval_age, eval_eth, eval_gen = test_eval\n...     t2 = eval_eth > 0.275\n...     assert t2, f'Your ethnicity accuracy on the test data should is too low! ({eval_eth})'\n>>> test_test_eval_eth(model, test_eval)\n",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> def test_test_eval_gen(model, test_eval):\n...     _, _, _, _, eval_age, eval_eth, eval_gen = test_eval\n...     t3 = eval_gen > 0.6\n...     assert t3, f'Your gender accuracy on the test data should is too low! ({eval_gen})'\n>>> test_test_eval_gen(model, test_eval)\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "unfreeze": {
     "name": "unfreeze",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_unfreeze(np, tf, model):\n...     t1 = np.sum([tf.keras.backend.count_params(w) for w in model.trainable_weights]) > 35792\n...     assert t1, 'The number of trainable parameters in the model should be ' + 'greater now after unfreezing the entire base model to make all of its parameters trainable. ' + 'Did you forget to recompile?'\n>>> test_unfreeze(np, tf, model)\n",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> def test_optimizer2(optimizer2):\n...     t1 = optimizer2.learning_rate.numpy() <= 0.001\n...     assert t1, 'You should use a smaller learning rate on when fine-tuning (see your optimizer2!)'\n>>> test_optimizer2(optimizer2)\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "you_did_it": {
     "name": "you_did_it",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_you_did_it(np):\n...     assert True, '!'\n>>> test_you_did_it(np)\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
