{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5,
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "### üß± BONUS: Writing Custom TensorFlow Layers and Models\n",
                "\n",
                "\u003e üß† **Why would we override `build()` at all?**\n",
                "\u003e\n",
                "\u003e Keras automatically tracks input shapes and will call `build()` for you behind the scenes the first time a layer sees real input data. You don‚Äôt usually need to override it unless you‚Äôre writing a **custom layer** where the shape of trainable weights depends on the shape of the input. For example, a custom dense layer might not know the input size until it sees it. Overriding `build()` lets you defer weight creation until the input shape is known.\n",
                "\u003e\n",
                "\u003e If you're using standard layers like `Dense`, `build()` is handled internally and you won't need to touch it. But for your ViT implementation, you‚Äôll likely need to override `build()` at least once.\n",
                "\n",
                "In Homework 5, you'll be asked to implement a Vision Transformer from scratch using custom TensorFlow layers. That means you'll need to:\n",
                "- Create your own subclasses of `tf.keras.layers.Layer`\n",
                "- Understand how and when to use `__init__()`, `build()`, and `call()`\n",
                "- Construct models that support `.summary()`\n",
                "\n",
                "Let‚Äôs walk through a toy example: a simple multilayer perceptron (MLP).\n",
                "\n",
                "#### ‚úèÔ∏è Step 1: Define a Custom Layer with `build()`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-04-17 22:10:02.943048: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-04-17 22:10:02.943085: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-04-17 22:10:02.943767: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-04-17 22:10:02.948711: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
                }
            ],
            "source": [
                "import tensorflow as tf\n",
                "\n",
                "class ScaledDense(tf.keras.layers.Layer):\n",
                "    def __init__(self, units):\n",
                "        super().__init__()\n",
                "        self.units = units\n",
                "\n",
                "    def build(self, input_shape):\n",
                "        self.w = self.add_weight(\"weights\", shape=(input_shape[-1], self.units), initializer=\"random_normal\")\n",
                "        self.b = self.add_weight(\"bias\", shape=(self.units,), initializer=\"zeros\")\n",
                "\n",
                "    def call(self, inputs):\n",
                "        return tf.nn.relu(tf.matmul(inputs, self.w) + self.b)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- `__init__`: stores configuration (like number of units)\n",
                "- `build`: creates weights **based on the shape of the input**\n",
                "- `call`: defines the forward computation"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### üß™ Step 2: Use It in a Model\n",
                "\n",
                "We wrap this custom layer into a `tf.keras.Model`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SimpleMLP(tf.keras.Model):\n",
                "    def __init__(self):\n",
                "        super().__init__()\n",
                "        self.dense1 = ScaledDense(16)\n",
                "        self.dense2 = ScaledDense(2)\n",
                "\n",
                "    def call(self, x):\n",
                "        x = self.dense1(x)\n",
                "        return self.dense2(x)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### üìè Step 3: Understand `.build()` and `.summary()`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Expected error when calling summary before build: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.\nModel: \"simple_mlp\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n scaled_dense (ScaledDense)  multiple                  144       \n                                                                 \n scaled_dense_1 (ScaledDens  multiple                  34        \n e)                                                              \n                                                                 \n=================================================================\nTotal params: 178 (712.00 Byte)\nTrainable params: 178 (712.00 Byte)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "2025-04-17 22:10:13.814837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20200 MB memory:  -\u003e device: 0, name: NVIDIA L4, pci bus id: 0000:3c:00.0, compute capability: 8.9\n"
                }
            ],
            "source": [
                "mlp = SimpleMLP()\n",
                "\n",
                "# Try to print summary before the model is built\n",
                "try:\n",
                "    mlp.summary()\n",
                "except Exception as e:\n",
                "    print(\"Expected error when calling summary before build:\", e)\n",
                "\n",
                "# Now build it with a known input shape\n",
                "mlp.build(input_shape=(None, 8))\n",
                "mlp.summary()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This is **exactly the kind of debugging you may need** when implementing your Vision Transformer in HW5.\n",
                "\n",
                "‚úÖ Now you‚Äôve seen how to:\n",
                "- Build models with custom layers\n",
                "- Handle shape dependencies with `.build()`\n",
                "- Produce readable `.summary()` outputs\n",
                "\n",
                "You‚Äôll use these same ideas in Homework 5, especially for the ViT implementation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                ""
            ]
        }
    ]
}
